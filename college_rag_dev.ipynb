{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7f8f47-f6d8-4578-8283-ff3a4b28004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6003738a-2931-4df8-9818-7eda2a3de484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyDZ1EVZ3PlwqWLmwQX-6WwyzgiOgifRZ0A\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "\n",
    "print(os.getenv(\"GEMINI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8deed5-12bc-413b-9bac-277e6fcf4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDFs loaded: 16\n",
      "Academic_Regulations.pdf -> characters: 1573\n",
      "BTech_Academic_Regulations.pdf -> characters: 1131\n",
      "BTech_Branch_Wise_Syllabus.pdf -> characters: 692\n",
      "BTech_Placement_Policy.pdf -> characters: 433\n",
      "BTech_Project_and_Internship_Guidelines.pdf -> characters: 404\n",
      "BTech_Student_Handbook.pdf -> characters: 365\n",
      "Examination_Guidelines.pdf -> characters: 1058\n",
      "gprec1.pdf -> characters: 59903\n",
      "Internal_and_External_Evaluation.pdf -> characters: 1446\n",
      "jnyuh.pdf -> characters: 57918\n",
      "Placement_Policy.pdf -> characters: 1038\n",
      "pune1.pdf -> characters: 43680\n",
      "syllabus.pdf -> characters: 452032\n",
      "TCS NQT IMP CONCEPTS (1).pdf -> characters: 601\n",
      "ugc.pdf -> characters: 175959\n",
      "vels.pdf -> characters: 80555\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "def load_pdf_text(file_path):\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        extracted = page.extract_text()\n",
    "        if extracted:\n",
    "            text += extracted + \"\\n\"\n",
    "    return text\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        text = load_pdf_text(os.path.join(DATA_DIR, file))\n",
    "        documents.append({\n",
    "            \"source\": file,\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "print(\"Total PDFs loaded:\", len(documents))\n",
    "for doc in documents:\n",
    "    print(doc[\"source\"], \"-> characters:\", len(doc[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2805e8b8-0f33-4743-90fc-37ac59065e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 2204\n",
      "\n",
      "Sample chunk:\n",
      "\n",
      "Academic Regulations â€“ Undergraduate Programs \n",
      "1. Introduction \n",
      "These academic regulations govern all undergraduate students enrolled in the institution. The \n",
      "objective is to maintain academic discipline, ensure fair evaluation, and promote holistic learning. \n",
      " \n",
      "2. Academic Year & Semester System \n",
      "â€¢ The academic year is divided into two semesters: \n",
      "o Odd Semester (Julyâ€“November) \n",
      "o Even Semester (Januaryâ€“May) \n",
      "â€¢ Each semester consists of: \n",
      "o Minimum 90 instructional days \n",
      "o Internal assessments \n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=500, overlap=100):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for doc in documents:\n",
    "    small_chunks = chunk_text(doc[\"text\"])\n",
    "    for ch in small_chunks:\n",
    "        chunks.append({\n",
    "            \"source\": doc[\"source\"],\n",
    "            \"text\": ch\n",
    "        })\n",
    "\n",
    "print(\"Total chunks created:\", len(chunks))\n",
    "print(\"\\nSample chunk:\\n\")\n",
    "print(chunks[0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bbc2505-cf58-4cbf-8b11-ab734cd7b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf85060-b97a-44c7-927d-055127623454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created for chunks: 2204\n",
      "Vector size: 384\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Take only text from chunks\n",
    "texts = [chunk[\"text\"] for chunk in chunks]\n",
    "\n",
    "# Convert text to vectors\n",
    "embeddings = embedder.encode(texts)\n",
    "\n",
    "print(\"Embeddings created for chunks:\", len(embeddings))\n",
    "print(\"Vector size:\", embeddings.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ada652-1021-48a5-9982-f6230582e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks stored in FAISS: 2204\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to FAISS\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "print(\"Total chunks stored in FAISS:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6120a381-8562-4cc3-a19c-43c30638d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index and chunks saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save FAISS index and chunks for Streamlit\n",
    "faiss.write_index(index, \"faiss.index\")\n",
    "np.save(\"chunks.npy\", chunks)\n",
    "\n",
    "print(\"FAISS index and chunks saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f023574-a750-4a92-b6e2-002db06b8917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved chunks:\n",
      "\n",
      "Source: gprec1.pdf\n",
      "on of subjects for Honors program offered in offline at the \n",
      "institution.  \n",
      "15. Attendance Requirements:  \n",
      "  \n",
      "i) A student shall be eligible to appear for the end examinations if he/she acquires a minimum of \n",
      "40% attendance in each subject and 75% of attendance in aggregate of all the subjects.  \n",
      "ii) Condonation of shortage of attendance in aggregate up to 10% (65% and above and below 75%) \n",
      "in each semester may be granted by the Principal.  \n",
      "iii) Shortage of Attendance below 65% in aggregate sha\n",
      "--------------------------------------------------\n",
      "Source: vels.pdf\n",
      "ear, for any Programme \n",
      "(Degree or Diploma), shall ordinarily be required to have a minimum cumulative \n",
      "attendance of 75% of the total lectures and practicals engaged during that Semester / \n",
      "Term / Year. A shorta ge of attendance of up to 10% alone can be condoned on an \n",
      "application filed by a candidate on medical grounds. \n",
      " In the case of Nursing degree programme, a candidate must have minimum of \n",
      "80% attendance in theory and practical in each course/subject for appe aring in the \n",
      "examination. \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Student question\n",
    "query = \"What is the minimum attendance required?\"\n",
    "\n",
    "# Convert question to vector\n",
    "query_embedding = embedder.encode([query])\n",
    "\n",
    "# Search FAISS for top 2 relevant chunks\n",
    "D, I = index.search(np.array(query_embedding), k=2)\n",
    "\n",
    "print(\"Retrieved chunks:\\n\")\n",
    "\n",
    "for idx in I[0]:\n",
    "    print(\"Source:\", chunks[idx][\"source\"])\n",
    "    print(chunks[idx][\"text\"])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae60c107-1cce-49fb-9f79-cb64b52cbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82599789-a1ec-46ef-82da-8d6b97aa7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gemini client using API key from environment variable\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Combine retrieved chunks into context\n",
    "context = \"\\n\\n\".join([chunks[idx][\"text\"] for idx in I[0]])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a college assistant chatbot.\n",
    "\n",
    "Answer the question ONLY using the context below.\n",
    "If the answer is not present, say \"Information not found in college documents.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04e46109-b8fa-440c-b19d-47603e9b3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-flash-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/deep-research-pro-preview-12-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "models/gemini-2.5-flash-native-audio-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "for m in client.models.list():\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7e3a6a9-0426-42d1-82d7-2e2c5d3ecd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum attendance required for a student to be eligible to appear for end examinations is 40% in each subject and 75% in aggregate of all subjects. Ordinarily, a minimum cumulative attendance of 75% of the total lectures and practicals engaged during that Semester / Term / Year is required. For the Nursing degree programme, a candidate must have a minimum of 80% attendance in theory and practical in each course/subject for appearing in the examination.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8f307c-196f-487c-aafd-c0d5009143d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ“ College Assistant Chatbot\n",
      "Type 'exit' to stop\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸŽ“ College Assistant Chatbot\")\n",
    "print(\"Type 'exit' to stop\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    \n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"Chatbot: Goodbye ðŸ‘‹\")\n",
    "        break\n",
    "\n",
    "    # Convert query to vector\n",
    "    query_embedding = embedder.encode([query])\n",
    "\n",
    "    # Retrieve top 2 chunks\n",
    "    D, I = index.search(np.array(query_embedding), k=2)\n",
    "\n",
    "    # Build context\n",
    "    context = \"\\n\\n\".join([chunks[idx][\"text\"] for idx in I[0]])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a college assistant chatbot.\n",
    "\n",
    "    Answer the question ONLY using the context below.\n",
    "    If the answer is not present, say \"Information not found in college documents.\"\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    print(\"\\nChatbot:\", response.text)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067ceb5-c82a-4626-9925-ba0dc2ca1a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
